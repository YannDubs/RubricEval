<|im_start|>system
You are a helpful instruction-following assistant.
<|im_end|>
<|im_start|>user
We are performing a holistic evaluation of powerful large language models (LLMs). To do so we need to come up with a diverse set of prompt to grade the LLM on. The responses to those prompts are expected to be extensive and complex. Each prompt should test one of the following categories of skills:
{categories}

Please generate {n} prompts for the category: {category}. Your answer should be a list of json objects that is then given to `evaluate_llm(prompts)`. Each containing the fields:
- `prompt`: the prompt to be given to the LLM. The prompt should contain all the information needed to complete the task. The prompt should be as diverse as possible, in terms of content, length/details, structure/style, and complexity. Make sure to include simpler but also harder task (in no particular order). The response to the prompt is expected to be extensive and complex as large language models are known to be very powerful.
- `category`: the category of the instruction
<|im_end|>